{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at our data. You can __download it from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "5 2010-12-01 08:26:00       7.65     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6) # By Default head funtion return 5 records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the description of the fields in this dataset:\n",
    "\n",
    "1. __InvoiceNo:__ Invoice number, a unique number assigned to each transaction.\n",
    "\n",
    "2. __StockCode:__ Product/item code. a unique number assigned to each distinct product.\n",
    "\n",
    "3. __Description:__ Product description\n",
    "\n",
    "4. __Quantity:__ The quantities of each product per transaction.\n",
    "\n",
    "5. __InvoiceDate:__ Invoice Date and time. The day and time when each transaction was generated.\n",
    "\n",
    "6. __CustomerID:__ Customer number, a unique number assigned to each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541909, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 541,909 transactions. That is a pretty good number for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description      1454\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     135080\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Since we have sufficient data, we will drop all the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo      0\n",
       "StockCode      0\n",
       "Description    0\n",
       "Quantity       0\n",
       "InvoiceDate    0\n",
       "UnitPrice      0\n",
       "CustomerID     0\n",
       "Country        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# again check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406829, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the StockCode to string datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['StockCode']= df['StockCode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the number of unique customers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4372"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = df[\"CustomerID\"].unique().tolist()\n",
    "len(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4,372 customers in our dataset. For each of these customers we will extract their buying history. In other words, we can have 4,372 sequences of purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to set aside a small part of the dataset for validation purpose. Therefore, I will use data of 90% of the customers to create word2vec embeddings. Let's split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369365, 8)\n",
      "(37464, 8)\n"
     ]
    }
   ],
   "source": [
    "# shuffle customer ID's\n",
    "random.shuffle(customers)\n",
    "\n",
    "# extract 90% of customer ID's\n",
    "customers_train = [customers[i] for i in range(round(0.9*len(customers)))]\n",
    "\n",
    "# split data into train and validation set\n",
    "train_df = df[df['CustomerID'].isin(customers_train)]\n",
    "validation_df = df[~df['CustomerID'].isin(customers_train)]\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create sequences of purchases made by the customers in the dataset for both the train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3935/3935 [00:10<00:00, 367.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# list to capture purchase history of the customers\n",
    "purchases_train = []\n",
    "\n",
    "# populate the list with the product codes\n",
    "for i in tqdm(customers_train):\n",
    "    temp = train_df[train_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
    "    purchases_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 437/437 [00:00<00:00, 507.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# list to capture purchase history of the customers\n",
    "purchases_val = []\n",
    "\n",
    "# populate the list with the product codes\n",
    "for i in tqdm(validation_df['CustomerID'].unique()):\n",
    "    temp = validation_df[validation_df[\"CustomerID\"] == i][\"StockCode\"].tolist()\n",
    "    purchases_val.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build word2vec Embeddings for Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3657270, 3693650)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "                 negative = 10, # for negative sampling\n",
    "                 alpha=0.03, min_alpha=0.0007,\n",
    "                 seed = 14)\n",
    "\n",
    "model.build_vocab(purchases_train, progress_per=200)\n",
    "\n",
    "model.train(purchases_train, total_examples = model.corpus_count, \n",
    "            epochs=10, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word2vec model\n",
    "model.save(\"word2vec_2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not plan to train the model any further, we are calling init_sims(), which will make the model much more memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3183, size=100, alpha=0.03)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract the vectors of all the words in our vocabulary and store it in one place for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all vectors\n",
    "X = model[model.wv.vocab]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Recommending Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We are finally ready with the word2vec embeddings for every product in our online retail dataset. Now our next step is to suggest similar products for a certain product or a product's vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a product-ID and product-description dictionary to easily map a product's description to its ID and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = train_df[[\"StockCode\", \"Description\"]]\n",
    "\n",
    "# remove duplicates\n",
    "products.drop_duplicates(inplace=True, subset='StockCode', keep=\"last\")\n",
    "\n",
    "# create product-ID and product-description dictionary\n",
    "products_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RED WOOLLY HOTTIE WHITE HEART.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the dictionary\n",
    "products_dict['84029E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "I have defined the function below. It will take a product's vector (n) as input and return top 6 similar products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_products(v, n = 6):\n",
    "    \n",
    "    # extract most similar products for the input vector\n",
    "    ms = model.similar_by_vector(v, topn= n+1)[1:]\n",
    "    \n",
    "    # extract name and similarity score of the similar products\n",
    "    new_ms = []\n",
    "    for j in ms:\n",
    "        pair = (products_dict[j[0]][0], j[1])\n",
    "        new_ms.append(pair)\n",
    "        \n",
    "    return new_ms        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our function by passing the vector of the product '90019A' ('SILVER M.O.P ORBIT BRACELET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SILVER M.O.P ORBIT BRACELET']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('BLACK VINTAGE  CRYSTAL EARRINGS', 0.8562676906585693),\n",
       " ('SILVER M.O.P ORBIT DROP EARRINGS', 0.8460784554481506),\n",
       " ('ANT COPPER RED BOUDICCA BRACELET', 0.8188737630844116),\n",
       " ('DROP DIAMANTE EARRINGS PURPLE', 0.8162773251533508),\n",
       " ('GOLD/M.O.P PENDANT ORBIT NECKLACE', 0.8090729117393494),\n",
       " ('SILVER LARIAT BLACK STONE EARRINGS', 0.8064510822296143)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(products_dict['90019A'])\n",
    "similar_products(model['90019A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Cool! The results are pretty relevant and match well with the input product. However, this output is based on the vector of a single product only. What if we want recommend a user products based on the multiple purchases he or she has made in the past?\n",
    "\n",
    "One simple solution is to take average of all the vectors of the products he has bought so far and use this resultant vector to find similar products. For that we will use the function below that takes in a list of product ID's and gives out a 100 dimensional vector which is mean of vectors of the products in the input list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_vectors(products):\n",
    "    product_vec = []\n",
    "    for i in products:\n",
    "        try:\n",
    "            product_vec.append(model[i])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    return np.mean(product_vec, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can recall, we have already created a separate list of purchase sequences for validation purpose. Now let's make use of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(purchases_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the first list of products purchased by a user is 314. We will pass this products' sequence of the validation set to the function *aggregate_vectors*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_vectors(purchases_val[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the function has returned an array of 100 dimension. It means the function is working fine. Now we can use this result to get the most similar products. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAM MAKING SET WITH JARS', 0.6791869401931763),\n",
       " ('SET OF 3 REGENCY CAKE TINS', 0.6773524880409241),\n",
       " ('SET OF 3 CAKE TINS PANTRY DESIGN ', 0.6668287515640259),\n",
       " ('ROSE DU SUD CUSHION COVER', 0.6576700806617737),\n",
       " ('PARTY BUNTING', 0.6521560549736023),\n",
       " ('SPOTTY BUNTING', 0.6507757902145386)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_products(aggregate_vectors(purchases_val[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, our system has recommended 6 products based on the entire purchase history of a user. Moreover, if you want to get products suggestions based on the last few purchases only then also you can use the same set of functions.\n",
    "\n",
    "Below I am giving only the last 10 products purchased as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PACK OF SIX LED TEA LIGHTS', 0.6577250957489014),\n",
       " (\"BOX OF 6 MINI 50'S CRACKERS\", 0.6457664966583252),\n",
       " (\"PAPER CHAIN KIT 50'S CHRISTMAS \", 0.6398783326148987),\n",
       " (\"6 GIFT TAGS 50'S CHRISTMAS \", 0.6396781802177429),\n",
       " ('BISCUIT TIN VINTAGE CHRISTMAS', 0.6326345205307007),\n",
       " (\" 50'S CHRISTMAS GIFT BAG LARGE\", 0.6296260356903076)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_products(aggregate_vectors(purchases_val[0][-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to play this code, try to get product recommendation for more sequences from the validation set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
